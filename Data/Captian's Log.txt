3-30-2019
Finished program to extract Life Expectancy data.  Found there were gaps in data coverage.
Worked on digitizing Memphis TN.  Ran into problem creating polygons.  Postulated the resolution was not high enough.

4-2-2019
Decided to pursue other data for physical health from 500 cities data.  Will need to justify use of other data, but will 
solve the issue of data gaps.  Narrowed it down to 2 possible implementations.  Either use the self-reported survey for
physical health, or use the 5 unhealthy behaviors provided to create a physical health indication.  We are currently 
leaning towards using the survey as it will be simpler.

4-9-2019
Got feedback from Bill.  Need to fix paper throughtout and update our metric of physical health.  Changed the conceptual 
and implementation diagram to reflect measure of physical health.
NOTE: Chose to exclude islands from Boston MA analysis.
Started working on Model Builder in ArcMap
Next step is to calculate centroids for census tracts.  Consider editing data processing python code to use pre-existing
centroid (geolocation column) for analysis.  Just need to seperate into latitude and longitude columns.

4-11-2019
Tim worked on the paper, going over edits.
I started identifying which mean (arithmetic or geometric) to use for data.

For outliers; choices:
Move to median; instead of analysis of varience, kruskall wallace? would work
Bill suggests using Kruskall Wallace method.
Calculate means with or without outliers.  Document the difference.  State what you're doing and why.

4-15-2019
Tim worked on the paper.  Says he made the edits.
Forgot to save my work.  :(

4-16-2019
Redid extraction of centroids from 500 cities data.
Tim worked on projecting city data.
I worked on the model builder.  It's almost done.  Just some issues with the selection.

4-17-2019
The damn model builder is still giving me problems.  For some reason, attempting to select by location is failing.  
So my good, fair, and poor distance tracts are not correct.  Excellent distance always seems to work though.  Go figure.

I started on calculating the median for attributes instead, because I hate what I'm doing now.

4-18-2019
Another day, another nickel.  Here we go again.
Jk, I'm not being paid for this.

Omg, the selection is working!  Just had to copy the selection results to a shape file, then transfer those to a layer 
for each selection.

Created tool to separate into good and poor health based on median calculated in csv file.

Tim is continuing to work on projecting the data.

4-21-2019
Finished the models in modelbuilder.  Woot!  Need to calibrate separate_by_health excess shapefiles for school
computer path though.  Left separate_by_distance as is, as it was working at school.
Next step is just to run them all at school once Tim is done with the shapefiles, then on to analysis!

4-22-2019
Tim is re-digitizing again.  For the last time.

Model now works!  Added styles for symbology in model builder for consistently colored output.

Ran it on Boston, Denver, and Las Vegas.

Denver's Proj_parks was in Detroit's folder.  Moved them into Denver's folder, which means Detroit's Proj_parks is 
missing.

Nashville, Oklahoma City, Portland, Seattle, and Washington were all saved in a newer version of ArcMap and need to be 
saved in an older format to open on school computers.

4-23-2019
Need Implementation, Conceptualization, and basemap layers for lab tomorrow for Atlas to look at.

Tim put a link to his Earth Point converter in the Green Space shapefiles file in google drive.
INCLUDE IT IN THE PAPER.

Managed to complete the health metric combination.  Updated model tool for it.

4-24-2019
Tim is manually moving the parks he digitized to try and line them up, so he'll finally be done digitizing.

Bill mentioned something about including spatial regression in the paper?
We should run spatialautocorrelation or G to show that there is clustering.  For that to make sense, we need to combine
our Helath and Distance metrics into one value that we can run on, or find an algorithm that allows running on multiple
fields.  Gonna ask Bill about it tomorrow.

4-25-2019
Distance model now combines into single data layer with metric for distance.
Excellent: 3
Good: 2
Fair: 1
Poor: 0

Start with summary statistics.  Basically what we did in lab.  What's the average health score?  Where are the places that are
above and below that score?  What the average distance to parks?  What's above and below that?

Then look at patterning.  Mainly looking at health.  Once we have that, put it over the parks.

Note the difference between Global and Local analysis.

Local Morans I analysis
Hot spot cold spot

You need to state the null hypothesis, which is that we expect deviations to be random, and we want that to be proven wrong.

When you do a global Moran's I (which is hotspot analysis) looks at the entire study area.  It calculates a mean for the entire area, and looks at each value and maps
the result.  The local is different.  It only looks at one census tract, and each surrounding census tract that are directly adjacent to it.  It does that for each
census tract.  You'll get a different result between the global and local Moran's I.  You'll get P scores and Z scores.  They're basically measures of how different 
you are from random.  Numbers between -1 and 1, how clustered you are, with random distribution being 0.  Trying to find the strength of that non-random distribution.
Up to you to determine why they're not random.  

So, we need to run that analysis on each city, and interpret our results.  

4-26-2019
NOTE: Make sure to include that "parks" included in analysis may include areas that are not actually parks, but could be service yards, playgrounds, etc.